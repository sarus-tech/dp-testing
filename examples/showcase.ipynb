{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![View On GitLab](https://img.shields.io/badge/Open%20in-GitLab-orange)](https://gitlab.com/your_username/your_repository/-/blob/main/examples/showcase.ipynb)\n",
    "![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)\n",
    "\n",
    "# Differential Privacy Testing\n",
    "\n",
    "Use this as a brief intro..\n",
    "\n",
    "---\n",
    "\n",
    "**Table of Contents**\n",
    "\n",
    "- [Introduction](#intro)\n",
    "- [DP testing in practice](#dp_testing_in_practice)\n",
    "  1) [Dataset Generation](#dataset_generation)\n",
    "  2) [Collecting DP Results](#collecting_dp_results)\n",
    "  3) [Partitioning Results](#paritioning_results)\n",
    "  4) [Compute Empirical Epsilons](#compute_empirical_epsilons)\n",
    "- [Conclusions](#conclusions)\n",
    "- [Theoretical Background & Refernces](#theoretical_backgroud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## How we test DP results:  \n",
    "\n",
    "What we do here. \n",
    "\n",
    "Mention that there are similar libraries doing so such as the Google's stochastic tester.\n",
    "The advantage of this one is the simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dp_testing_in_practice\"></a>\n",
    "## Experimental settings\n",
    "\n",
    "In this section we go from theory to practice. To do so we need to:\n",
    "1) **Dataset Generation**: *Brief description*\n",
    "2) **Collecting DP Results**: *Brief description*\n",
    "3) **Partitioning Results**: *Brief description*\n",
    "4) **Compute Empirical Epsilons**: *Brief description*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dataset_generation\"></a>\n",
    "### Dataset Generation\n",
    "\n",
    "*Content Dataset Generation goes here.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you don't have a postgres database up and running, run this code to create one.\n",
    "# %%capture\n",
    "# # Load the database\n",
    "# # Inspired by https://colab.research.google.com/github/tensorflow/io/blob/master/docs/tutorials/postgresql.ipynb#scrollTo=YUj0878jPyz7\n",
    "# !sudo apt-get -y -qq update\n",
    "# !sudo apt-get -y -qq install postgresql-14\n",
    "# # Start postgresql server\n",
    "# !sudo sed -i \"s/port = 5432/port = 5433/g\" /etc/postgresql/14/main/postgresql.conf\n",
    "# !sudo service postgresql start\n",
    "# # Set password\n",
    "# !sudo -u postgres psql -U postgres -c \"ALTER USER postgres PASSWORD 'pyqrlew-db'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dp_tester.generate_datasets import generate_D_0_dataset, generate_adj_datasets, D_1\n",
    "\n",
    "generate_D_0_dataset()\n",
    "generate_adj_datasets(D_1, user_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"collecting_dp_results\"></a>\n",
    "### Collecting DP Results\n",
    "\n",
    "*Content Collecting DP Results goes here.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dp_tester.generate_dp_results import generate_dp_results\n",
    "from dp_tester.query_executors import SqlAlchemyQueryExecutor\n",
    "from dp_tester.dp_rewriters import PyqrlewDpRewriter\n",
    "from dp_tester.table_renamers import PyqrlewTableRenamer\n",
    "from dp_tester.generate_datasets import D_0\n",
    "import json\n",
    "\n",
    "query = \"SELECT store_id, SUM(spent) FROM transactions GROUP BY store_id\"\n",
    "epsilon = 1.0\n",
    "delta = 1e-4\n",
    "runs = 5000\n",
    "\n",
    "query_executor = SqlAlchemyQueryExecutor()\n",
    "dp_rewriter = PyqrlewDpRewriter(engine=query_executor.engine)\n",
    "table_renamer = PyqrlewTableRenamer(dp_rewriter.dataset)\n",
    "\n",
    "results = generate_dp_results(\n",
    "    non_dp_query=query,\n",
    "    epsilon=epsilon,\n",
    "    delta=delta,\n",
    "    runs=runs,\n",
    "    dp_rewriter=dp_rewriter,\n",
    "    query_executor=query_executor,\n",
    "    table_renamer=table_renamer,\n",
    "    d_0=D_0,\n",
    "    adjacent_ds=[D_1],\n",
    ")\n",
    "\n",
    "# save results if needed\n",
    "with open(\"results.json\", \"w\") as outfile:\n",
    "    json.dump(obj=results, fp=outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"paritioning_results\"></a>\n",
    "### Partitioning Results\n",
    "\n",
    "*Content Dataset Generation goes here.*\n",
    "Here we want to associate a result into a single bucket. There are many ways to do so.\n",
    "We then generate counts.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dp_tester.generate_datasets import N_STORES\n",
    "from dp_tester.partitioners import QuantityOverGroups\n",
    "from dp_tester.analyzer import partition_results_to_bucket_ids, counts_from_indexes\n",
    "\n",
    "NBINS = 20\n",
    "\n",
    "# read results if saved\n",
    "with open(\"results.json\") as infile:\n",
    "    results = json.load(infile)\n",
    "\n",
    "partitioner = QuantityOverGroups(groups=range(N_STORES))\n",
    "partitioned_results = partitioner.partition_results(results)\n",
    "partitioner.generate_buckets(partitioned_results, nbuckets=NBINS)\n",
    "\n",
    "bucket_ids = partition_results_to_bucket_ids(partitioned_results, partitioner.bucket_id)\n",
    "\n",
    "d_0_d_1_counts = {}\n",
    "\n",
    "for group in partitioner.groups:\n",
    "    buckets_ids_d_0 = bucket_ids[f\"{D_0}-{group}\"]\n",
    "    buckets_ids_d_1 = bucket_ids[f\"{D_1}-{group}\"]\n",
    "\n",
    "    counts_d_0 = counts_from_indexes(buckets_ids_d_0, NBINS)\n",
    "    counts_d_1 = counts_from_indexes(buckets_ids_d_1, NBINS)\n",
    "\n",
    "    d_0_d_1_counts[f\"{D_0}-{D_1}-{group}\"] = (counts_d_0, counts_d_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"compute_empirical_epsilons\"></a>\n",
    "### Compute Empirical Epsilon\n",
    "\n",
    "*Content Compute Empirical Epsilon goes here.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dp_tester.analyzer import empirical_epsilon\n",
    "\n",
    "COUNT_THRESHOLD = 5\n",
    "\n",
    "empirical_epsilons = {}\n",
    "for name, (count_d_0, counts_d_1) in d_0_d_1_counts.items():\n",
    "    empirical_epsilons[name] = empirical_epsilon(\n",
    "        count_d_0, counts_d_1, delta=delta, counts_threshold=COUNT_THRESHOLD\n",
    "    )\n",
    "\n",
    "empirical_epsilons_values = list(empirical_epsilons.values())\n",
    "max_eps = max(empirical_epsilons_values)\n",
    "\n",
    "print(f\"Epsilon used during the experiment: {epsilon}\")\n",
    "print(f\"Max empirical epsilon found: {max_eps}\")\n",
    "print(f\"Did the test passed? {max_eps < epsilon}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"conclusions\"></a>\n",
    "## Conclusions\n",
    "\n",
    "In this notebook, we covered:\n",
    "\n",
    "- A summary of what was accomplished.\n",
    "- Key takeaways and observations.\n",
    "- Possible next steps or further reading.\n",
    "\n",
    "Thank you for exploring our library!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"theoretical_backgroud\"></a>\n",
    "## Theoretical Background & References\n",
    "\n",
    "- Differencial Privacy\n",
    "- Wilson paper\n",
    "- Kariutz paper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
